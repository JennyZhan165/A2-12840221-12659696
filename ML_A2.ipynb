{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML A2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JennyZhan165/A2-12840221-12659696/blob/master/ML_A2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLg5gpJU1d6G",
        "colab_type": "text"
      },
      "source": [
        "#Assignment 2: Practical Machine Learning Project\n",
        "## Group member: 12840221 Yunhan Zhan / 12659696 Chaoran Fu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eNZj8EQ4d-H",
        "colab_type": "text"
      },
      "source": [
        "### Github link: <>\n",
        "### Youtube Video link:<https://www.youtube.com/watch?v=6kUn-R1DlB0&feature=youtu.be>\n",
        "### Dataset link:  <https://www.kaggle.com/russellyates88/suicide-rates-overview-1985-to-2016/downloads/suicide-rates-overview-1985-to-2016.zip/1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRQPBB0g4uWz",
        "colab_type": "text"
      },
      "source": [
        "## 1. Introduction\n",
        "### 1.1 Define problem\n",
        "\n",
        "The dataset that we used for this project is called ‘Suicide Rates Overview 1985 to 2016’ from Kaggle. There are 12 columns totally: country, year, sex, age, suicides_no, population, suicides/100k pop, country-year, HDI for year, gdp_for_year, gdp_per_capita and generation. The main data mining problem that we found is to deal with predicting the feature of suicides_no which means the number of suicides under specific conditions. \n",
        "\n",
        "### 1.2 Discuss the Algorithm\n",
        "\n",
        "Python will be the main language in the following processing to solve the problem. Colab will be the environment for us to implement machine learning project. Additionally, this report will use few machine learning software libraries, such as scikit-learn, np and panda.\n",
        "\n",
        "There are different regressors that can be used to predict suicides_no, for instance, Decision Tree, Random Forest and Support Vector Regression. Eventually, we will compare the accuracy rate for each of the models in order to choose the most suitable model. Additionally, before we build each regressors, for prediction purpose, we are supposed to split the dataset into two parts, one is training data, and another is testing data. In this project, I will set 80% of the training data and 20% for the testing data as default.\n",
        "\n",
        "The main purpose of this data mining project is to provide input columns that can correctly produce an output of suicides_no by using accurate regressors. However, few columns such as, 'HID for year' and 'country-year' are filtered from the processing because these columns are irrelevant values or have a huge number of missing values that won’t help us to predict the target value. After analysis this dataset, the input of the data mining projects will be country, year, sex, age, population, suicides_no, suicides/100k pop, generation, gdp_for_year and gdp_per_capita. Then, the suicides_no will be the output of the algorithm. In the following part, many data pre-processing steps were used to drop of those useless values and also fully preparation and transform before passing the dataset to models. Except from that, correlation is a method that was used to assist with checking how strong each relationship is between those features after preparation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_p8fhyY41JB",
        "colab_type": "text"
      },
      "source": [
        "##2. Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XyJg6oIT5Gr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "550ff3da-caea-4a75-ef6d-34e0d35eae79"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "dataset = panda.read_csv( \"/content/gdrive/My Drive/master.csv\")\n",
        "dataset=dataset.rename(columns={'suicides/100k pop':'suicides100kPop','HDI for year':'HDIForYear',' gdp_for_year ($) ':'GdpForYearMoney',\n",
        "                          'gdp_per_capita ($)':'GdpPerCapitalMoney'})\n",
        "dataset.head()"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "      <th>year</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>suicides_no</th>\n",
              "      <th>population</th>\n",
              "      <th>suicides100kPop</th>\n",
              "      <th>country-year</th>\n",
              "      <th>HDIForYear</th>\n",
              "      <th>GdpForYearMoney</th>\n",
              "      <th>GdpPerCapitalMoney</th>\n",
              "      <th>generation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Albania</td>\n",
              "      <td>1987</td>\n",
              "      <td>male</td>\n",
              "      <td>15-24 years</td>\n",
              "      <td>21</td>\n",
              "      <td>312900</td>\n",
              "      <td>6.71</td>\n",
              "      <td>Albania1987</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2,156,624,900</td>\n",
              "      <td>796</td>\n",
              "      <td>Generation X</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Albania</td>\n",
              "      <td>1987</td>\n",
              "      <td>male</td>\n",
              "      <td>35-54 years</td>\n",
              "      <td>16</td>\n",
              "      <td>308000</td>\n",
              "      <td>5.19</td>\n",
              "      <td>Albania1987</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2,156,624,900</td>\n",
              "      <td>796</td>\n",
              "      <td>Silent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Albania</td>\n",
              "      <td>1987</td>\n",
              "      <td>female</td>\n",
              "      <td>15-24 years</td>\n",
              "      <td>14</td>\n",
              "      <td>289700</td>\n",
              "      <td>4.83</td>\n",
              "      <td>Albania1987</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2,156,624,900</td>\n",
              "      <td>796</td>\n",
              "      <td>Generation X</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Albania</td>\n",
              "      <td>1987</td>\n",
              "      <td>male</td>\n",
              "      <td>75+ years</td>\n",
              "      <td>1</td>\n",
              "      <td>21800</td>\n",
              "      <td>4.59</td>\n",
              "      <td>Albania1987</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2,156,624,900</td>\n",
              "      <td>796</td>\n",
              "      <td>G.I. Generation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Albania</td>\n",
              "      <td>1987</td>\n",
              "      <td>male</td>\n",
              "      <td>25-34 years</td>\n",
              "      <td>9</td>\n",
              "      <td>274300</td>\n",
              "      <td>3.28</td>\n",
              "      <td>Albania1987</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2,156,624,900</td>\n",
              "      <td>796</td>\n",
              "      <td>Boomers</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   country  year     sex  ... GdpForYearMoney  GdpPerCapitalMoney       generation\n",
              "0  Albania  1987    male  ...   2,156,624,900                 796     Generation X\n",
              "1  Albania  1987    male  ...   2,156,624,900                 796           Silent\n",
              "2  Albania  1987  female  ...   2,156,624,900                 796     Generation X\n",
              "3  Albania  1987    male  ...   2,156,624,900                 796  G.I. Generation\n",
              "4  Albania  1987    male  ...   2,156,624,900                 796          Boomers\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NOYOQIlT3Dc",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Challenge\n",
        "\n",
        "The challenges that we faced are quite a lot. On the one hand, heavily analytical work, because of the large size of the dataset and huge time span from 1985 to 2016. On the other hand, because the data mining problem is to predict the number of suicides (suicides_no), so we have to use methods to ignore these irrelevant columns, in order to get a high accuracy models. Apart from that, we are predicting numeric variable instead of categorical, so use regressors, not classifiers. Then, a few columns are supposed to transfer from categorical to numerical since the models only accept numbers.    \n",
        "\n",
        "### 2.2 Data Description\n",
        "#### 2.2.1 country\n",
        "\n",
        "This column means the different names of countries where suicides happened. Moreover, this column is a categorical data type and it has 101 different categories. The highest records are Iceland, Austria, Netherlands and Mauritius categories (382 values), and the lowest record is Mongolia, only has 10 values. Because this column is a categorical value, we can’t use it as an input directly, so data type transferring is required for this column if it can help us to predict the target value. \n",
        "\n",
        "\n",
        "#### 2.2.2 year\n",
        "\n",
        "This column is the year from 1985 to 2016 and it is a discrete data type. In 2009, it had the highest value of suicides and 2016 had the lowest value. Additionally, year can be used as an input for the processing of predicting the number of suicides. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGwk_02YVUlc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "a2d7dde0-c7a7-4aaa-f96c-170639316e8c"
      },
      "source": [
        "dataset['year'].value_counts().plot('bar')"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3b8f045cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAELCAYAAADQsFGkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCkAiIgkSgFARCRR/w/v1MSkm5wQDwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKWRCWkpUZjU",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2.3 sex\n",
        "\n",
        "This data is a categorical data type. In the dataset, it has 2 data values, male and female. We can see from the figure that the number of each gender are the same number: 13910.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUNmrfUjVcAC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "f4f4916b-5658-4d82-ab50-ffe302bb4375"
      },
      "source": [
        "dataset['sex'].value_counts().plot('pie')"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3b8ed59630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPkAAADuCAYAAAD7nKGzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FESEHTd7UfT_",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2.4 age\n",
        "\n",
        "This data is pretty complicated because it’s a range of the values and consists of numerical and categorical values. It was divided into 6 categories, 5-14 years, 15-24 years, 55-74 years, 25-34 years, 35-54 years and 75+ years. This data can be used in further processing as input and transformation is needed because it combines two data types. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5FTy9iNVtM_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "1ccdf46b-ab05-4f30-cc95-6929155c287c"
      },
      "source": [
        "dataset['age'].value_counts().plot('bar')"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3b8ec1f128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEtCAYAAAABRbePAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGZtJREFUeJzt3XuUJWV97vHvwwyCitxHgjPooBAJ\nnhjQEfBozjESYLgIaNBgFOaw0FlZQSV6lgkkJohKDnqOEjGCgYBcvCCihgkhkAmCmEQYhotc5TBy\nEThcBrnJnYHn/FFvy6bpprtndu/aXe/zWatX136ruvfv5WX201X1VpVsExER9Vmr7QIiIqIdCYCI\niEolACIiKpUAiIioVAIgIqJSCYCIiEolACIiKpUAiIioVAIgIqJSs9su4MVsuummnj9/fttlRETM\nKJdffvl9tudMtN1QB8D8+fNZvnx522VERMwokm6bzHY5BBQRUakEQEREpRIAERGVSgBERFQqARAR\nUakEQEREpRIAERGVSgBERFRqqC8EW13zD/vngb7frUfvOdD3S//6K/3rny73rYuyBxARUalO7gFE\nREyHru3hZA8gIqJSCYCIiEolACIiKpUAiIioVAIgIqJSCYCIiEolACIiKpUAiIioVAIgIqJSCYCI\niEolACIiKpUAiIioVAIgIqJSCYCIiEolACIiKpUAiIioVAIgIqJSCYCIiEolACIiKpUAiIioVAIg\nIqJSCYCIiEolACIiKjXpAJA0S9KVks4pr7eUdKmkFZK+I+klpX2d8npFWT+/53ccXtpvlLRbvzsT\nERGTN5U9gEOBG3pefx44xvZWwAPAwaX9YOCB0n5M2Q5J2wL7A28AFgLHSZq1ZuVHRMTqmlQASJoH\n7An8Q3kt4J3AWWWTU4F9y/I+5TVl/c5l+32AM2w/afsWYAWwQz86ERERUzfZPYC/Bf4MeLa83gR4\n0Paq8voOYG5ZngvcDlDWP1S2/3X7GD/za5IWS1ouafnKlSun0JWIiJiKCQNA0l7AvbYvH0A92D7B\n9gLbC+bMmTOIt4yIqNLsSWzzNmBvSXsA6wLrA18GNpQ0u/yVPw+4s2x/J7AFcIek2cAGwC972kf0\n/kxERAzYhHsAtg+3Pc/2fJqTuD+0/QHgQmC/stki4OyyvKS8pqz/oW2X9v3LLKEtga2BZX3rSURE\nTMlk9gDG8+fAGZI+B1wJnFTaTwJOl7QCuJ8mNLB9naQzgeuBVcAhtp9Zg/ePiIg1MKUAsH0RcFFZ\nvpkxZvHYfgJ47zg/fxRw1FSLjIiI/suVwBERlUoARERUKgEQEVGpBEBERKUSABERlUoARERUKgEQ\nEVGpBEBERKUSABERlUoARERUKgEQEVGpBEBERKUSABERlUoARERUKgEQEVGpBEBERKUSABERlUoA\nRERUKgEQEVGpBEBERKUSABERlUoARERUKgEQEVGpBEBERKUSABERlUoARERUKgEQEVGpBEBERKUS\nABERlUoARERUKgEQEVGpBEBERKUSABERlUoARERUKgEQEVGpCQNA0rqSlkn6qaTrJB1Z2reUdKmk\nFZK+I+klpX2d8npFWT+/53cdXtpvlLTbdHUqIiImNpk9gCeBd9r+HWA7YKGknYDPA8fY3gp4ADi4\nbH8w8EBpP6Zsh6Rtgf2BNwALgeMkzepnZyIiYvImDAA3Hikv1y5fBt4JnFXaTwX2Lcv7lNeU9TtL\nUmk/w/aTtm8BVgA79KUXERExZZM6ByBplqSrgHuBpcDPgQdtryqb3AHMLctzgdsByvqHgE1628f4\nmd73WixpuaTlK1eunHqPIiJiUiYVALafsb0dMI/mr/Ztpqsg2yfYXmB7wZw5c6brbSIiqjelWUC2\nHwQuBN4KbChpdlk1D7izLN8JbAFQ1m8A/LK3fYyfiYiIAZvMLKA5kjYsyy8FdgFuoAmC/cpmi4Cz\ny/KS8pqy/oe2Xdr3L7OEtgS2Bpb1qyMRETE1syfehM2BU8uMnbWAM22fI+l64AxJnwOuBE4q258E\nnC5pBXA/zcwfbF8n6UzgemAVcIjtZ/rbnYiImKwJA8D21cD2Y7TfzBizeGw/Abx3nN91FHDU1MuM\niIh+y5XAERGVSgBERFQqARARUakEQEREpRIAERGVSgBERFQqARARUakEQEREpRIAERGVSgBERFQq\nARARUakEQEREpRIAERGVSgBERFQqARARUakEQEREpRIAERGVSgBERFQqARARUakEQEREpRIAERGV\nSgBERFQqARARUakEQEREpRIAERGVSgBERFQqARARUakEQEREpRIAERGVSgBERFQqARARUakEQERE\npRIAERGVSgBERFQqARARUakEQEREpSYMAElbSLpQ0vWSrpN0aGnfWNJSSTeV7xuVdkk6VtIKSVdL\nelPP71pUtr9J0qLp61ZERExkMnsAq4D/aXtbYCfgEEnbAocBF9jeGrigvAbYHdi6fC0GjocmMIAj\ngB2BHYAjRkIjIiIGb8IAsH2X7SvK8q+AG4C5wD7AqWWzU4F9y/I+wGluXAJsKGlzYDdgqe37bT8A\nLAUW9rU3ERExaVM6ByBpPrA9cCmwme27yqq7gc3K8lzg9p4fu6O0jdc++j0WS1ouafnKlSunUl5E\nREzBpANA0nrA94A/tf1w7zrbBtyPgmyfYHuB7QVz5szpx6+MiIgxTCoAJK1N8+H/TdvfL833lEM7\nlO/3lvY7gS16fnxeaRuvPSIiWjCZWUACTgJusP2lnlVLgJGZPIuAs3vaDyyzgXYCHiqHis4HdpW0\nUTn5u2tpi4iIFsyexDZvAw4ArpF0VWn7C+Bo4ExJBwO3Ae8r684F9gBWAI8BBwHYvl/SZ4HLynaf\nsX1/X3oRERFTNmEA2P53QOOs3nmM7Q0cMs7vOhk4eSoFRkTE9MiVwBERlUoARERUKgEQEVGpBEBE\nRKUSABERlUoARERUKgEQEVGpBEBERKUSABERlUoARERUKgEQEVGpBEBERKUSABERlUoARERUKgEQ\nEVGpBEBERKUSABERlUoARERUKgEQEVGpBEBERKUSABERlUoARERUKgEQEVGpBEBERKUSABERlUoA\nRERUKgEQEVGpBEBERKUSABERlUoARERUKgEQEVGpBEBERKUSABERlUoARERUKgEQEVGpBEBERKUm\nDABJJ0u6V9K1PW0bS1oq6abyfaPSLknHSloh6WpJb+r5mUVl+5skLZqe7kRExGRNZg/gFGDhqLbD\ngAtsbw1cUF4D7A5sXb4WA8dDExjAEcCOwA7AESOhERER7ZgwAGxfDNw/qnkf4NSyfCqwb0/7aW5c\nAmwoaXNgN2Cp7fttPwAs5YWhEhERA7S65wA2s31XWb4b2KwszwVu79nujtI2XvsLSFosabmk5StX\nrlzN8iIiYiJrfBLYtgH3oZaR33eC7QW2F8yZM6dfvzYiIkZZ3QC4pxzaoXy/t7TfCWzRs9280jZe\ne0REtGR1A2AJMDKTZxFwdk/7gWU20E7AQ+VQ0fnArpI2Kid/dy1tERHRktkTbSDp28A7gE0l3UEz\nm+do4ExJBwO3Ae8rm58L7AGsAB4DDgKwfb+kzwKXle0+Y3v0ieWIiBigCQPA9vvHWbXzGNsaOGSc\n33MycPKUqouIiGmTK4EjIiqVAIiIqFQCICKiUgmAiIhKJQAiIiqVAIiIqFQCICKiUgmAiIhKJQAi\nIiqVAIiIqFQCICKiUgmAiIhKJQAiIiqVAIiIqFQCICKiUgmAiIhKJQAiIiqVAIiIqFQCICKiUgmA\niIhKJQAiIiqVAIiIqFQCICKiUgmAiIhKJQAiIiqVAIiIqFQCICKiUgmAiIhKJQAiIiqVAIiIqFQC\nICKiUgmAiIhKJQAiIiqVAIiIqFQCICKiUgMPAEkLJd0oaYWkwwb9/hER0RhoAEiaBXwV2B3YFni/\npG0HWUNERDQGvQewA7DC9s22nwLOAPYZcA0REQHI9uDeTNoPWGj7Q+X1AcCOtj/Ss81iYHF5+Xrg\nxoEVCJsC9w3w/QYt/ZvZuty/LvcNBt+/19ieM9FGswdRyVTYPgE4oY33lrTc9oI23nsQ0r+Zrcv9\n63LfYHj7N+hDQHcCW/S8nlfaIiJiwAYdAJcBW0vaUtJLgP2BJQOuISIiGPAhINurJH0EOB+YBZxs\n+7pB1jCBVg49DVD6N7N1uX9d7hsMaf8GehI4IiKGR64EjoioVAIgIqJSCYCIiEolAKITJK0laf22\n65gukjaS9Ma265gOXRw7Se+V9Iqy/ClJ35f0prbrGq3qAJD0BUnrS1pb0gWSVkr6YNt19UsF/ftW\n6d/LgWuB6yV9su26+kXSRaV/GwNXACdK+lLbdfVD18cO+Cvbv5L0duD3gZOA41uu6QWqDgBgV9sP\nA3sBtwJbAV36n7Dr/du29G9f4F+ALYED2i2przYo/XsPcJrtHWk+TLqg62P3TPm+J3CC7X8GXtJi\nPWOqPQDWLt/3BL5r+6E2i5kGne+fpLVpPkSW2H4a6NK85tmSNgfeB5zTdjF91vWxu1PS3wN/CJwr\naR2G8PN26AoasCWSfga8GbhA0hzgiZZr6qeu9+9rNHs2LwculvQa4OFWK+qvI2kumlxh+zJJrwVu\narmmfun62L2PZux2s/0gsDFDuPdd7YVgktYCdgJ+Bjxk+5lyPPIVtu9ut7o1V0n/9rN9Zk+bgFm2\nV7VXWX+UZ2d8zPYxbdfSb5WM3XW2t2m7lolUGwAAkq60vX3bdUyXCvo3lHdY7BdJy2zv0HYd06GC\nsTsb+KjtX7Rdy4upPQD+D/AT4Pvu4H+ICvp3NM091r8DPDrSbvv+1orqI0nH0JzHGd2/K1orqk8q\nGLuLge2BZTy/f3u3VtQYag+AX9Ecg1xFc2xcgG13Yk5yBf27ZYxm237twIuZBpIuHKPZtt858GL6\nrIKx++9jtdv+0aBreTFVB0BERM2G7olggyZpI2BrYN2RNtsXt1dRf1XQv/8CbMvz+3daexX1l6Q9\ngTfw/P59pr2K+qfLYydpJ+ArwG/RzP+fBTw6bHvfVQeApA8Bh9I8mewqmlkzPwFm/C42VNG/I4B3\n0HyInAvsDvw70JUPka8BLwN+D/gHYD+aY8ozXtfHDvg7mgdefRdYABwI/GarFY2h9usADgXeAtxm\n+/doTto82G5JfdX1/u0H7Azcbfsg4HeADdotqa/+q+0DgQdsHwm8lSH8EFlNXR87bK+gmdr6jO2v\nAwvbrmm0qvcAgCdsPyEJSevY/pmk17ddVB91vX+P235W0qpyM7F7ef4zp2e6x8v3xyS9CvglsHmL\n9fRT18fusfLY26skfQG4iyH8g7v2ALhD0obAPwJLJT0A3NZyTf3U9f4tL/07EbgceITmEFdXnFP6\n979pbgZnmkNBXdD1sTuA5gP/I8DHacLtD1qtaAyZBVSUaVsbAOfZfqrtevqtgv7NB9a3fXXLpUyL\nci+ZdTt4P6fOjp2klwKvtn1j27WMZ+h2SQZN0tslHVTm5/4EmNt2Tf3U5f6p8UFJf237VuBBSZ25\nclbSyyT9laQTbT8JvFLSXm3X1Q8VjN27aCZenFdebydpSbtVvVDVAVBmIvw5cHhpWhv4RnsV9VfX\n+wccR3Ni9P3l9a+Ar7ZXTt99HXiSpo8AdwKfa6+cvur62H0a2IEy6cL2VTS3vB4qVQcA8G5gb8ql\n2rb/H/CKVivqr673b0fbh1DucGr7AYbwnutr4HW2vwA8DWD7MZqrubug62P39BiH64bueHvtAfBU\nuUeOAcrdMruk6/17utx5caR/c4Bn2y2pr54qx5FH+vc6mj2CLuj62F0n6Y+AWZK2lvQV4D/bLmq0\n2gPgzPLQhg0lfRj4N5pZCV3R9f4dC/yA5tj4UTQXEv1NuyX11adpjiFvIembwAXAn7VaUf90few+\nSnMF95PAt4CHgD9ttaIxVD8LSNIuwK40u9bn217ackl9VUH/tqG5oEjABbZvaLmkvpK0Cc0V3AIu\nsX1fyyX1TZfHTtJv276m7TomUnUASPoo8I1y/LFzKujfF4GTbF/fdi3TQdL3aB4mfp7tLh0eqWHs\nfgysA5wCfHNYp+/WfghoM+AySWdKWlieStQlXe/fDcCJki6V9MeSOnUrAeB44APATZKO7thV3J0e\nO9u/C3yQ5gKwyyV9q+yND5Wq9wDg14+i2xU4iOamTWfS/GXy81YL65Ou9w+gfDAeRDOl8D+AE22P\ndS/9Gal8OL4f+EvgdprzON8oD1Kf0SoYu1k0D74/luaZxwL+wvb3Wy2sqH0PgDJL5u7ytQrYCDir\n3L9jxut6/8o/sG3K133AT4FPSDqj1cL6pJwD+B/Ah4ArgS8DbwJm/LmcLo+dpDeqeaLbDTR3332X\n7d8qy0PznOeq9wAkHUpzm9b7aO6x8o+2n1bz0OqbbL+u1QLXUAX9OwbYC/ghzV7Nsp51N9qe0YdM\nJP0AeD1wOnCK7bt61s3oZ+pWMHY/ovk3d5btx0etO8D26e1U9ny13wxuY+A9tp93g7Ryl8IuXHLf\n9f5dDXzK9qNjrOvCbQWOHe9wyEz+8C86PXa2x3wkZFk3FB/+UPkeQEREzao/BxARUasEQETENJL0\nyrZrGE8CoJC0d9s1TKcK+vcnbdcwXSRt1HYN06lLYydp41FfmwDLJG0kaeO26xutypPAkt4zugn4\nqqTZAMMyR3d1VdC/T4xuAg6XtC6A7S8NvqppdQHN1M8Zr4Kxu48XPnVvLs890e21A6/oRVQZAMB3\ngPNpnkM6cnXsy4F30QzSjP6ApPv9OxI4F7iO5/o3i27d6rpXl67g7vrYfRLYBfjkyL2AJN1ie+ie\nBQCVzgKS9BbgaJo5useXtqEdpKmqoH+vBr4I3AwcafsxSTfbHqq/rtaEpANHFmk+NP96ZJ3t01op\nqg8qGbt5NBd73Q4cAfx0WPtX5TkA25fRpPRLJF1YHkXXmSSsoH+/sP1emvurL5W0X9s1TYMty9d8\nmpuKze95PWPVMHa27yh9vIjmiu2XtVvR+KrcA+gl6VXA3wILhjWl10QF/Xs5zX3zd7T931ouZ1pI\nusJ2J84B9Kpk7F5K82S3a9uuZSzVB0DEsJN0pe3t264j1oykg2x/ve06elV5CEjSb0g6XtJXJW0i\n6dOSri63Td687frWlKQ39iyvLelTkpZI+htJQ7s7OlmSrih9mtH3MpqCA9ouoF8krS/pf0k6Xc0j\nE3vXHddWXQNyZNsFjFZlANA8pOF6mpM0FwKPA3sCPwa+1l5ZfXNKz/LRwFY0J95eSjf6txGwIXCh\npGWSPl4OdXXSsB4+WE1fpzmx/T1gf0nfk7ROWbdTe2X1R/lDcqyva2iezzFUqjwE1LtLLekXtl/d\ns+4q29u1V92aG9W/q4C3lLuAimZGwhtf/DcMt95j4pJ+l+Ze8u+hufXut22f0GZ9a0rSQtvnleUN\ngC8BbwGuBT5u+54261sTo/99SfpLYA9gb2DpTD/XIekeYDdg9FP4BPyn7aH6Q6XWPYDefo+eUteF\n/yYbSHq3pD8A1hl5cEh5NkCnEt/2j23/Cc3FNp8H3tpySf3Q+3D0LwJ30VzDcRnw961U1D/rlNuR\nA2D7KJoH3FwMbNJaVf1zDrCe7dtGfd1KMytoqNR6IdjZktaz/YjtT400StoK+L8t1tUvP6L5iwrg\nEkmb2b5H0m/QXKk4071gjGw/A5xXvrpkQc9fzMdIWtRqNWvun2geivJvIw22T5F0N/CV1qrqE9sH\nv8i6PxpvXVuqPAQUMcwk3UFz2EfAITTTCF3WXT3TD+HVRtLiYT0s2YXDHX0h6Zy2a5hOkobyf8B+\n6dj4nUhza4T1gFOBTaGZvQZc1WJd06JjYzeWP267gPHUeghoLHPbLmCazfQnSE2kM+Nne8zpgrbv\npnnEZ9d0ZuzGMbT3csoewHOubLuAaXZv2wVMs86Mn6SPlfvJ1KIzYzeOd7VdwHhyDiBiyEh6CHgU\n+DnwbeC7tle2W1WsDklvp3nG8bW2/7Xtekarcg9A0sKe5Q0knVQu1viWpKG7WGOqKrgSuNPjR3On\nzHnAZ4E3A9dLOk/SIkkz+rbJXR87Sct6lj8M/B3N+ZwjJB3WWmHjqDIA6PY8a+j+lcBdHz/bftb2\nv5Zpha8CjgMW0oTDTNb1sVu7Z3kxsEs5p7Mr8IF2ShpfTgJ3b541PP+k0848dyXwxcBPW6ppunR9\n/CgX8i0BlnRhD65HF8duLTWP8FyL5hD7SgDbj0pa1W5pL1RrALxSzaPpBKwvSX7uZEgX9oo2kPRu\nmr4870pgSV046dP18fvD8VbYfmyQhUyDro/dBsDlNP2zpM1t3yVpPYZwNlCtATAyzxqem2e9skPz\nrLt+JXCnx892F65GH0/Xx27+OKueBd49wFImJbOAIiIq1YVdrtUiaRtJO5dds972heP9zEwiaQc1\nzwZG0raSPiFpj7brmg6S3l76t2vbtcTqk3RQ2zXUpso9AEkfo7nHyg3AdsChts8u62b84/ckHQHs\nTnOIbymwI81zD3YBzi93YJyxJC2zvUNZ/jDNWP6AZqbFP9k+us36YvWMvjV7TL9aA+Aa4K22H5E0\nHzgLON32l9WBx++V/m1H8zDxu4F5th9W83zSS2f6zcRGPe/gMmAP2yvVPGP2Etu/3W6FMR5JV4+3\nCvhN2+uMsz6mQa0ngdey/QiA7VslvQM4S9JrGMIz9athVbk98mOSfm77YQDbj0t6tuXa+mFGTbWL\n59mMF3lgyuDLqVutAXCPpO1sXwVQ9gT2Ak4GuvDX41OSXlamDL55pLE8XaoLATCjptrF84w8MOUF\nM34kXTT4cupW6yGgeTR/Jd89xrq32f6PFsrqG0nr2H5yjPZNgc1tX9NCWdOuXCS1me1b2q4lYiao\nMgAiIqLiaaAREbVLAEREVCoBEBFRqQRARESl/j8xY87f8sqxcgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5tS-hzcUg6k",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2.5 population\n",
        "\n",
        "Population means the number of people in the country at the time of suicide in each period, and also it’s a numerical data. Additionally, because this data can be used to calculate the suicides_no and suicides rate, we consider it as an input data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iDFiZX8ZMZw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "b3b3585b-f167-4d19-e2fc-df79cb1b9f45"
      },
      "source": [
        "dataset['population'].describe()"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    2.782000e+04\n",
              "mean     1.844794e+06\n",
              "std      3.911779e+06\n",
              "min      2.780000e+02\n",
              "25%      9.749850e+04\n",
              "50%      4.301500e+05\n",
              "75%      1.486143e+06\n",
              "max      4.380521e+07\n",
              "Name: population, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI30_FAmUiq9",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2.6 suicide_no\n",
        "\n",
        "This column is a numerical data type and it records the number of suicides in a particular phase. The mean value is 242.57, and standard deviation of this column data is 902.048, the max number is 22338. Suicides_no is used for the output value of the data mining problem, and the accuracy after output are used to compare the accuracy in various algorithms.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdrKUxyQVv0o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "0bad2c9f-cbea-4b46-8a9f-9fb3ad995d40"
      },
      "source": [
        "dataset['suicides_no'].describe()"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    27820.000000\n",
              "mean       242.574407\n",
              "std        902.047917\n",
              "min          0.000000\n",
              "25%          3.000000\n",
              "50%         25.000000\n",
              "75%        131.000000\n",
              "max      22338.000000\n",
              "Name: suicides_no, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJaVVRlKUkkK",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2.7 suicides/100k pop\n",
        "\n",
        "Suicides/100k pop(suicide rate) is a numerical data that is closely related to the population and the suicides_no. Furthermore, the mean of suicide rate is 12.816, and standard deviation is 18.96. Because the suicide rate directly affects the output value suicide number, it will be used as the input value of the data classification. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5h3hADxV3px",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "ecb17042-e28d-4d11-bef4-ab060032305d"
      },
      "source": [
        "dataset['suicides100kPop'].describe()"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    27820.000000\n",
              "mean        12.816097\n",
              "std         18.961511\n",
              "min          0.000000\n",
              "25%          0.920000\n",
              "50%          5.990000\n",
              "75%         16.620000\n",
              "max        224.970000\n",
              "Name: suicides100kPop, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgJUO690Ukdx",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2.8 generation\n",
        "\n",
        "This column has 6 different values and it is a categorical data type. Actually, generation is age-dependent value, G.I. Generation corresponds to people who were born between 1901 and 1927, and Silent corresponds to people who were born between 1925 and 1942 ,and Generation X corresponds to people who were born between 1960 and 1980, and Boomers are people who were born between 1946 and 1964, and Millennials are people who were born between 1980 and early 2000, finally, the mean of Generation Z are people who were born between mid1990 and 2000. Generation X has the most value that is 6408, and generation Z has the lowest value that is 1470.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6epyFCIEWBy7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "3570cb17-f071-4e24-e316-af012637352c"
      },
      "source": [
        "dataset['generation'].value_counts().plot('bar')"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3b8ebb68d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAE+CAYAAACEB8e6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoPBpUuCUn8V",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2.9 gdp_for_year and gdp_per_capita \n",
        "\n",
        "Gdp_for_year describes Gross Domestic Product at the year of suicides and Gdp_per_captia describes Gross Domestic Product per capita at the year of suicides. These two sets of data are all numerical value. The total GDP can obtain the per capita GDP. Also, both of these data have a high positive correlation with suicides_no so that they are used as input values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qssSgjUm45yp",
        "colab_type": "text"
      },
      "source": [
        "##3. Methodology\n",
        "### 3.1 Data Pre-Processing\n",
        "#### 3.1.1 Missing value\n",
        "In this dataset, only ‘HDI for year’ has missing values, as shown below, which may reduce the accuracy of models. Because the number of missing values is more than half of the dataset (19,000) so we can’t do simple replacement of this column, then we decided to delete it to ensure the accuracy of models reached the exception.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d-g0nYEWSWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Check all the null value in the dataset\n",
        "dataset.isnull().sum()\n",
        "#Because there are more than 50% missing value of HDIForYear, so we drop this column\n",
        "dataset = dataset.drop('HDIForYear',axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ794FLCWpkl",
        "colab_type": "text"
      },
      "source": [
        "Furthermore, we give each category an integer value when the data type is categorical. For example, we give the number of the first country to 1, because only integer values can be used in regressions to do the data analytics, then delete the column and append the value to a new column called Transforcountry. Moreover, there are three more datas in the dataset, sex, age and generation, so we do the same conversion as the previous method. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w1kV3AjWqk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "trans = LabelEncoder()\n",
        "Transforcountry=trans.fit_transform(dataset['country'])\n",
        "transMappings = {index: label for index, label in \n",
        "                  enumerate(trans.classes_)}\n",
        "dataset['Transforcountry'] = Transforcountry\n",
        "dataset.Transforcountry.unique()\n",
        "#Removing the Category column as a column with numbers is appended\n",
        "dataset = dataset.drop('country',axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXt4PXHtWw_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#trans = LabelEncoder()\n",
        "Transforsex=trans.fit_transform(dataset['sex'])\n",
        "transMappings = {index: label for index, label in \n",
        "                  enumerate(trans.classes_)}\n",
        "dataset['Transforsex'] = Transforsex\n",
        "dataset.Transforsex.unique()\n",
        "#Removing the Category column as a column with numbers is appended\n",
        "dataset = dataset.drop('sex',axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fmOl3RAWxcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#trans = LabelEncoder()\n",
        "Transforage=trans.fit_transform(dataset['age'])\n",
        "transMappings = {index: label for index, label in \n",
        "                  enumerate(trans.classes_)}\n",
        "dataset['Transforage'] = Transforage\n",
        "dataset.Transforage.unique()\n",
        "#Removing the Category column as a column with numbers is appended\n",
        "dataset = dataset.drop('age',axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-soRLE6Wz47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#trans = LabelEncoder()\n",
        "Transforgeneration=trans.fit_transform(dataset['generation'])\n",
        "transMappings = {index: label for index, label in \n",
        "                  enumerate(trans.classes_)}\n",
        "dataset['Transforgeneration'] = Transforgeneration\n",
        "dataset.Transforgeneration.unique()\n",
        "dataset = dataset.drop('generation',axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qjh22CnHWfHl",
        "colab_type": "text"
      },
      "source": [
        "#### 3.1.2 Data Redundancy\n",
        "If we look closer to the dataset, the column ‘country-year’ is the combination of ‘country’ and ‘year’, therefore we can ignore this column if we keep  ‘country’ and ‘year’ as inputs. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWOnjlGiXCCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Country-year is similar to the combination of year and country, and becuase keep both, so can drop country-year\n",
        "dataset = dataset.drop('country-year', axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFmfp7nEXF6U",
        "colab_type": "text"
      },
      "source": [
        "Additionally, there are more than 4000 columns of suicides_no and suicides rate (suicides100kPop). In order to enhance the accuracy of models, we can try to drop these rows which includes zero values.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr87rCiWXIfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# drop all the zero values in suicides_no\n",
        "dataset = dataset[(dataset[['suicides_no','suicides100kPop']] != 0).all(axis=1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSgtbDLTXM_n",
        "colab_type": "text"
      },
      "source": [
        "In addition to deal with columns, this dataset contains few unnecessary characters, for instance, the ‘,’ in the column of ‘GdpForYearMoney’, and Python cannot do statistics of these characters, so we use the following code to delete them.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6Fto2QaXNTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to delete the symbol in the dataset\n",
        "checksymbol = dataset.columns\n",
        "dataset[checksymbol]=dataset[checksymbol].replace({'\\,':''}, regex = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywl4L6_AWQDH",
        "colab_type": "text"
      },
      "source": [
        "#### 3.1.3 Data type conversion and appending the column\n",
        "As we can see below, the initial datatype of the entire dataset, for few columns, the data type of country, age, sex and generation is object as default. Since models only accept numeric input, transfer the data type of these columns from category to numerical is necessary. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsEPnI57Wf14",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7b503267-900a-4d8b-da4f-cb8d72f685ec"
      },
      "source": [
        "#Check the datatype of each features\n",
        "dataset.dtypes"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "year                    int64\n",
              "suicides_no             int64\n",
              "population              int64\n",
              "suicides100kPop       float64\n",
              "GdpForYearMoney        object\n",
              "GdpPerCapitalMoney      int64\n",
              "Transforcountry         int64\n",
              "Transforsex             int64\n",
              "Transforage             int64\n",
              "Transforgeneration      int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV-f7t0icJeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#change GdpForYearMoney to int\n",
        "dataset['GdpForYearMoney'] = dataset.GdpForYearMoney.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uljPU0auW8Ut",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Implement Algorithm\n",
        "#### 3.2.1 Decision Tree\n",
        "\n",
        "Decision tree is a data analytics method that is used for regression analysis. Also, Decision tree always produce high accuracy and only accepts numeric input. In the previous section, we did data type conversion and data redundancy to gain the correct format of input data.\n",
        "\n",
        "Firstly, we create two lists X and Y, and then we insert the whole prepared dataset without the data ‘suicides100kPop’ from X and then keep ‘suicides100kPop’ in list Y. In the next step, we partition the X and Y to X training, X testing, and Y training and Y testing, and we divide 20% data to testing data, and then use an internal random number generator to choose 100 data randomly. The below code shows the accuracy of the Decision Tree. The accuracy of Decision tree classifier is 99.9% \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bT7Jy3GXVHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "#Partitioning data\n",
        "X= dataset.drop('suicides_no',axis=1)\n",
        "Y= dataset['suicides_no']\n",
        "# testing and training data of decision tree\n",
        "dt_Xtraining, dt_Xtesting, dt_Ytraining, dt_Ytesting = train_test_split(X, Y, test_size=0.20, random_state = 100) \n",
        "model =  DecisionTreeRegressor(random_state= 100)\n",
        "model.fit(dt_Xtraining, dt_Ytraining)\n",
        "y_pred = model.predict(X) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7NSLbvmdEO_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d53784c2-3b25-4da4-9fe0-856049fdb356"
      },
      "source": [
        "#Accuracy for Decision Tree\n",
        "print(\"Accuracy for Decision Tree:\", r2_score(Y, y_pred))"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for Decision Tree: 0.9991121948787185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cl8LV7aXUaS",
        "colab_type": "text"
      },
      "source": [
        "#### 3.2.2 Random Forest\n",
        "\n",
        "Random forest can also be used for regression analysis. Random forest model is a supervised learning method that creates a bunch of random trees that predict processes. Most parameters are similar to decision tree. In this classifier, Random forest model uses bootstrap sampling to select from the test set to make the deviation of the results smaller.\n",
        "\n",
        "In the next step, we partition the X and Y to X training, X testing, and Y training and Y testing, and we give 20% data to testing data, and we use an internal random number generator to choose 100 data randomly. The below code shows the accuracy of the Random Forest Regressor. The accuracy of Random Forest is 68.6%\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MllJquaYDqS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "3e7dcec2-923c-4250-96fb-6a19fc88b241"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "#from sklearn.datasets import make_regression\n",
        "\n",
        "rf_Xtrainging, rf_Xtesting, rf_Ytraining, rf_Ytesting = train_test_split(X, Y, test_size=0.20, random_state = 100) \n",
        "regr = RandomForestRegressor(max_depth=2, random_state=0,n_estimators=100)\n",
        "regr.fit(rf_Xtrainging, rf_Ytraining)"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
              "                      max_features='auto', max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                      n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
              "                      warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBO6iJ_vdoih",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0fd9ef91-257c-4978-d8ce-638d74c1f00b"
      },
      "source": [
        "print(\"Accuracy for Random-Forest:\", r2_score(Y, regr.predict(X)))"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for Random-Forest: 0.6865944579475496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3HK60ctXqxW",
        "colab_type": "text"
      },
      "source": [
        "#### 3.2.3 Support Vector Regression\n",
        "\n",
        "The last regression method that we used is Support Vector Regression (SVR) which can maintain the maximum margin of all significant features of the algorithm. We partitioned the X and Y to X training, X testing, and Y training and Y testing, and we give 20% data to testing data, so there are 5564 values in the testing dataset. We use all the parameters as default and the accuracy of Support Vector Regression is very bad.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND1Ezy1fXrcN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f32f03e5-579f-419d-cffe-e6b125f7d0a2"
      },
      "source": [
        "X_training, X_testing, Y_training, Y_testing = train_test_split(X, Y, test_size=0.20, random_state = 100)\n",
        "print('Training Features Shape:', X_training.shape)\n",
        "print('Training Labels Shape:', Y_training.shape)\n",
        "print('Testing Features Shape:', X_testing.shape)\n",
        "print('Testing Labels Shape:', Y_testing.shape)\n",
        "from sklearn.svm import SVR\n",
        "import numpy as np\n",
        "\n",
        "clf = SVR(gamma = 'scale', C = 50.0, epsilon = 0.5)\n",
        "clf.fit(dt_Xtraining,dt_Ytraining)\n",
        "y_pred = clf.predict(X)"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Features Shape: (18831, 9)\n",
            "Training Labels Shape: (18831,)\n",
            "Testing Features Shape: (4708, 9)\n",
            "Testing Labels Shape: (4708,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ouglNmFcfzX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b264b74-de4c-417d-f910-35babf50950a"
      },
      "source": [
        "print(\"Accuracy for SVR:\", r2_score(Y, y_pred)) "
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for SVR: 0.1308785360039908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs5gldcR5Ufe",
        "colab_type": "text"
      },
      "source": [
        "## 4. Evaluation\n",
        "\n",
        "Decision Tree has disadvantages. Because it makes the optimal decision at every step, choosing the best result in a given step does not ensure that the prediction is always optimal. When any parameter changed, the accuracy of Decision Tree is still more than 90%.\n",
        "\n",
        "In terms of Random Forest, many scholars believe that Random Forest model is powerful classification and regression analytics too, and this regressor is much more powerful than a single decision tree. Moreover, because the same features will be selected in many base trees, if we do not select features randomly, Random Forest will bring us insurmountable problems.\n",
        "\n",
        "Support Vector Regression is related learning algorithms, analysing data, so it is also perfect for doing regression and classification analytics, but we can see through the result, this model may not be suitable for this data. \n",
        "\n",
        "In order to improve the accuracy of SVR, we modified the parameter. The accuracy of Support Vector Regression (C is 1) is 3.9%, and when C is 50, the accuracy is 13%, as we mentioned eariler. Through experiments, we found that the larger the C value, the higher the accuracy, and this is because the classifier in SVG will make as few mistakes as possible, but large C value will lead to overfitting. We found that the C value between 50-100 is the best result.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7Ut5gPhYbpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "import numpy as np\n",
        "\n",
        "clf = SVR(gamma = 'scale', C = 1.0, epsilon = 0.5)\n",
        "clf.fit(dt_Xtraining,dt_Ytraining)\n",
        "y_pred = clf.predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBiHoMhAdxno",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e7c5a68-b43a-489d-be8c-0a9ceda3c42f"
      },
      "source": [
        "print(\"Accuracy for SVR:\", r2_score(Y, y_pred)) "
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for SVR: 0.03916746663196036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFA6PdmDYySq",
        "colab_type": "text"
      },
      "source": [
        "In order to consider different situations to compare the accuracy, less relevant columns with the target values can be ignored, following is the figure of correlation matrix after data pre-processing. The correlation between target value suicides_no and ‘year’ is only 0.004146 so we can consider it as an outlier. After we drop the column of ‘year’ in the input, the accuracy of each regressor are slightly decreased. Therefore, we decided to keep ‘year’ feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oGXpfXBY0Wb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "c8befda9-92f4-4ec7-9a76-61cdefe812ab"
      },
      "source": [
        "dataset.corr(method='spearman')"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>suicides_no</th>\n",
              "      <th>population</th>\n",
              "      <th>suicides100kPop</th>\n",
              "      <th>GdpForYearMoney</th>\n",
              "      <th>GdpPerCapitalMoney</th>\n",
              "      <th>Transforcountry</th>\n",
              "      <th>Transforsex</th>\n",
              "      <th>Transforage</th>\n",
              "      <th>Transforgeneration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>year</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.011497</td>\n",
              "      <td>0.008853</td>\n",
              "      <td>-0.046190</td>\n",
              "      <td>0.203511</td>\n",
              "      <td>0.336439</td>\n",
              "      <td>0.021220</td>\n",
              "      <td>0.000864</td>\n",
              "      <td>-0.001653</td>\n",
              "      <td>0.244788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>suicides_no</th>\n",
              "      <td>-0.011497</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.702524</td>\n",
              "      <td>0.546282</td>\n",
              "      <td>0.578116</td>\n",
              "      <td>0.122907</td>\n",
              "      <td>0.062630</td>\n",
              "      <td>0.199559</td>\n",
              "      <td>-0.063591</td>\n",
              "      <td>-0.097829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>population</th>\n",
              "      <td>0.008853</td>\n",
              "      <td>0.702524</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.147747</td>\n",
              "      <td>0.730791</td>\n",
              "      <td>0.079644</td>\n",
              "      <td>0.056472</td>\n",
              "      <td>-0.079179</td>\n",
              "      <td>-0.145925</td>\n",
              "      <td>-0.057434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>suicides100kPop</th>\n",
              "      <td>-0.046190</td>\n",
              "      <td>0.546282</td>\n",
              "      <td>-0.147747</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.034768</td>\n",
              "      <td>0.085478</td>\n",
              "      <td>0.037863</td>\n",
              "      <td>0.454473</td>\n",
              "      <td>0.136992</td>\n",
              "      <td>-0.061426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GdpForYearMoney</th>\n",
              "      <td>0.203511</td>\n",
              "      <td>0.578116</td>\n",
              "      <td>0.730791</td>\n",
              "      <td>-0.034768</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.646972</td>\n",
              "      <td>0.062476</td>\n",
              "      <td>-0.043888</td>\n",
              "      <td>0.037914</td>\n",
              "      <td>0.064508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GdpPerCapitalMoney</th>\n",
              "      <td>0.336439</td>\n",
              "      <td>0.122907</td>\n",
              "      <td>0.079644</td>\n",
              "      <td>0.085478</td>\n",
              "      <td>0.646972</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.025544</td>\n",
              "      <td>-0.000503</td>\n",
              "      <td>0.001461</td>\n",
              "      <td>0.071380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Transforcountry</th>\n",
              "      <td>0.021220</td>\n",
              "      <td>0.062630</td>\n",
              "      <td>0.056472</td>\n",
              "      <td>0.037863</td>\n",
              "      <td>0.062476</td>\n",
              "      <td>0.025544</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.007434</td>\n",
              "      <td>0.004131</td>\n",
              "      <td>0.010396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Transforsex</th>\n",
              "      <td>0.000864</td>\n",
              "      <td>0.199559</td>\n",
              "      <td>-0.079179</td>\n",
              "      <td>0.454473</td>\n",
              "      <td>-0.043888</td>\n",
              "      <td>-0.000503</td>\n",
              "      <td>-0.007434</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.005495</td>\n",
              "      <td>0.003555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Transforage</th>\n",
              "      <td>-0.001653</td>\n",
              "      <td>-0.063591</td>\n",
              "      <td>-0.145925</td>\n",
              "      <td>0.136992</td>\n",
              "      <td>0.037914</td>\n",
              "      <td>0.001461</td>\n",
              "      <td>0.004131</td>\n",
              "      <td>0.005495</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.224788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Transforgeneration</th>\n",
              "      <td>0.244788</td>\n",
              "      <td>-0.097829</td>\n",
              "      <td>-0.057434</td>\n",
              "      <td>-0.061426</td>\n",
              "      <td>0.064508</td>\n",
              "      <td>0.071380</td>\n",
              "      <td>0.010396</td>\n",
              "      <td>0.003555</td>\n",
              "      <td>0.224788</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        year  suicides_no  ...  Transforage  Transforgeneration\n",
              "year                1.000000    -0.011497  ...    -0.001653            0.244788\n",
              "suicides_no        -0.011497     1.000000  ...    -0.063591           -0.097829\n",
              "population          0.008853     0.702524  ...    -0.145925           -0.057434\n",
              "suicides100kPop    -0.046190     0.546282  ...     0.136992           -0.061426\n",
              "GdpForYearMoney     0.203511     0.578116  ...     0.037914            0.064508\n",
              "GdpPerCapitalMoney  0.336439     0.122907  ...     0.001461            0.071380\n",
              "Transforcountry     0.021220     0.062630  ...     0.004131            0.010396\n",
              "Transforsex         0.000864     0.199559  ...     0.005495            0.003555\n",
              "Transforage        -0.001653    -0.063591  ...     1.000000            0.224788\n",
              "Transforgeneration  0.244788    -0.097829  ...     0.224788            1.000000\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERrqQBU15Ar2",
        "colab_type": "text"
      },
      "source": [
        "## 5. Conclusion\n",
        "\n",
        "In this data mining project, we used 3 different regressors to build and train data, Decision Tree, Random Forest and Support Vector Regression. We sorted the datasets into 2 parts, testing data and training data for the prediction. We inserted the same data to each regressor, and make sure each regressor that has a configuration for producing the highest accuracy, and reducing bias.\n",
        "\n",
        "The highest accuracy is produced by Decision Tree in this data mining project. Decision Tree has a great classification purpose in this project because it only choose the best prediction and not end until the prediction ends. Furthermore, In the Support Vector Regression, by testing and adjusting the C value, we increased the exact accuracy from 5% to 13%, but results still did not reach our expectations. It may be that the model is not suitable for this dataset, or the previous data pre-processing method cannot work correctly with the model. Finally, the accuracy of Random Forest is 68.98% \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEaYt9et5GfG",
        "colab_type": "text"
      },
      "source": [
        "##6. Ethical\n",
        "\n",
        "The reason of making this model to find the signals of increasing suicide rates globally. There would be inaccuracies in the prediction due to: Insufficient sample data, not enough parameters and special circumstances which cannot be forecasted.\n",
        "\n",
        "If we follow the utilitarian approach, we need to consider all circumstances or possibilities, then we are not able to make the rules, or, the rules may include too many parameters and is extremely difficult to come up. Because, right or wrong of this model is decided by the outcome, but the future is hard to predict, so it's hard to make a model given so many uncertainties need to be considered. The current regressions are following the Kantian rule-based approach. The rules are limited, so it cannot cover all possible cases, for instance, we can’t use this model to predict all the suicides number globally.\n",
        "\n",
        "In this model, we try to include as many rules as we can, to make the prediction more accurate, and this is the best we can do, but the prediction cannot be exact as the actual number. The number for prediction is just for studying and researching, not really for suicides prevention.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjVLYDPy5ZGI",
        "colab_type": "text"
      },
      "source": [
        "## 7. Consolidated Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONa_ptL-AMs0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as panda\n",
        "import numpy as np\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "from sklearn import metrics\n",
        "from IPython.display import Image  \n",
        "from sklearn.tree import export_graphviz\n",
        "import graphviz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp-opJfxG1oQ",
        "colab_type": "code",
        "outputId": "5abcf28e-debd-4faa-f829-a4879b00029c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V-BvLtwCp_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = panda.read_csv( \"/content/gdrive/My Drive/master.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9EQd-VV6yGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=dataset.rename(columns={'suicides/100k pop':'suicides100kPop','HDI for year':'HDIForYear',' gdp_for_year ($) ':'GdpForYearMoney',\n",
        "                          'gdp_per_capita ($)':'GdpPerCapitalMoney'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dd9EUh_HdCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGs98uusFFLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Check all the null value in the dataset\n",
        "dataset.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAX3jPx7FHnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Because there are more than 50% missing value of HDIForYear, so we drop this column\n",
        "dataset = dataset.drop('HDIForYear',axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FAKyx1ipMly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataset.drop('year',axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOsBsd3qFN2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to delete the symbol in the dataset\n",
        "checksymbol = dataset.columns\n",
        "dataset[checksymbol]=dataset[checksymbol].replace({'\\,':''}, regex = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lDEsVTAjq8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check all the non-zero values in the dataset\n",
        "dataset.count(axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mT7_FR80NfU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# drop all the zero values in suicides_no\n",
        "dataset = dataset[(dataset[['suicides_no','suicides100kPop']] != 0).all(axis=1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myDiH6Dvm2CJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Country-year is similar to the combination of year and country, and becuase keep both, so can drop country-year\n",
        "dataset = dataset.drop('country-year', axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noFfQVnyxufa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Check the datatype of each features\n",
        "dataset.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFZkMhUWXMsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#change GdpForYearMoney to int\n",
        "dataset['GdpForYearMoney'] = dataset.GdpForYearMoney.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hDc51vBulLF",
        "colab_type": "text"
      },
      "source": [
        "Identify related data type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3ssTUqB0uVS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "186ff3b3-4ab5-46bb-a287-ae0874543980"
      },
      "source": [
        "dataset['population'].describe()"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    2.782000e+04\n",
              "mean     1.844794e+06\n",
              "std      3.911779e+06\n",
              "min      2.780000e+02\n",
              "25%      9.749850e+04\n",
              "50%      4.301500e+05\n",
              "75%      1.486143e+06\n",
              "max      4.380521e+07\n",
              "Name: population, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc-cpmNuHUNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['country'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ubJ3bZZpnh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['year'].value_counts().plot('bar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLhlNVIau1TM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['sex'].value_counts().plot('pie')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EymHjNEjV76e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['generation'].value_counts().plot('bar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkvmnnk_Vl-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['age'].value_counts().plot('bar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLWOV51BVubR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['suicides_no'].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6xGK8H4WK7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['suicides100kPop'].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPASPcY5p7Ic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['sex'].value_counts().plot('bar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77N9CSm9vY0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['Transforgeneration'].value_counts().plot('bar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWVFoKvovHKl",
        "colab_type": "text"
      },
      "source": [
        "The following code is for transfor the data from string to number， if we drop these data already, we do not need to do the following code "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUr2VAmB5L7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trans = LabelEncoder()\n",
        "Transforcountry=trans.fit_transform(dataset['country'])\n",
        "transMappings = {index: label for index, label in \n",
        "                  enumerate(trans.classes_)}\n",
        "dataset['Transforcountry'] = Transforcountry\n",
        "dataset.Transforcountry.unique()\n",
        "#Removing the Category column as a column with numbers is appended\n",
        "dataset = dataset.drop('country',axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYNGlN-oKCg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#trans = LabelEncoder()\n",
        "Transforsex=trans.fit_transform(dataset['sex'])\n",
        "transMappings = {index: label for index, label in \n",
        "                  enumerate(trans.classes_)}\n",
        "dataset['Transforsex'] = Transforsex\n",
        "dataset.Transforsex.unique()\n",
        "#Removing the Category column as a column with numbers is appended\n",
        "dataset = dataset.drop('sex',axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uNi1uJ9KDG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#trans = LabelEncoder()\n",
        "Transforage=trans.fit_transform(dataset['age'])\n",
        "transMappings = {index: label for index, label in \n",
        "                  enumerate(trans.classes_)}\n",
        "dataset['Transforage'] = Transforage\n",
        "dataset.Transforage.unique()\n",
        "#Removing the Category column as a column with numbers is appended\n",
        "dataset = dataset.drop('age',axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz6pz7uIA0bO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#trans = LabelEncoder()\n",
        "Transforgeneration=trans.fit_transform(dataset['generation'])\n",
        "transMappings = {index: label for index, label in \n",
        "                  enumerate(trans.classes_)}\n",
        "dataset['Transforgeneration'] = Transforgeneration\n",
        "dataset.Transforgeneration.unique()\n",
        "dataset = dataset.drop('generation',axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKYDyoOJefg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.corr(method='spearman')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXGGIkKrVVGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Partitioning data\n",
        "X= dataset.drop('suicides_no',axis=1)\n",
        "Y= dataset['suicides_no']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mTcyrz_8DhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# testing and training data of decision tree\n",
        "dt_Xtraining, dt_Xtesting, dt_Ytraining, dt_Ytesting = train_test_split(X, Y, test_size=0.20, random_state = 100) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrQzkBXLFoyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model =  DecisionTreeRegressor(random_state= 100)\n",
        "model.fit(dt_Xtraining, dt_Ytraining)\n",
        "y_pred = model.predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRaRIkdoHDBj",
        "colab_type": "code",
        "outputId": "23204f59-4dba-4981-d4fb-526b22a8125c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Accuracy for Decision Tree\n",
        "print(\"Accuracy for Decision Tree:\", r2_score(Y, y_pred)) "
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for Decision Tree: 0.9990662624532448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA6ILmqOvmUY",
        "colab_type": "text"
      },
      "source": [
        "Following code is used to do SVR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pizAAQq9Op9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_training, X_testing, Y_training, Y_testing = train_test_split(X, Y, test_size=0.20, random_state = 100)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slnZPVbWP7x-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Training Features Shape:', X_training.shape)\n",
        "print('Training Labels Shape:', Y_training.shape)\n",
        "print('Testing Features Shape:', X_testing.shape)\n",
        "print('Testing Labels Shape:', Y_testing.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYwHUhdIdCZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "import numpy as np\n",
        "\n",
        "clf = SVR(gamma = 'scale', C = 1.0, epsilon = 0.5)\n",
        "clf.fit(dt_Xtraining,dt_Ytraining)\n",
        "y_pred = clf.predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3vW5-jEP0LM",
        "colab_type": "code",
        "outputId": "bcb77409-a038-407a-dc36-31ba26cc8f42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Accuracy for SVR:\", r2_score(Y, y_pred)) "
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for SVR: 0.039167466631960024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsUshsibvvMD",
        "colab_type": "text"
      },
      "source": [
        "Following code is used to do Random forest regession"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rAqEl6bWAIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "#from sklearn.datasets import make_regression\n",
        "\n",
        "rf_Xtrainging, rf_Xtesting, rf_Ytraining, rf_Ytesting = train_test_split(X, Y, test_size=0.20, random_state = 100) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpB8FWyGWAXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regr = RandomForestRegressor(max_depth=2, random_state=0,n_estimators=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_Otzx5uz9yF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regr.fit(rf_Xtrainging, rf_Ytraining)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufJtURSC0Y6s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17615985-2e89-49a5-9d79-8db4488c616e"
      },
      "source": [
        "print(\"Accuracy for Random-Forest:\", r2_score(Y, regr.predict(X)))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for Random-Forest: 0.6835021803817833\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}